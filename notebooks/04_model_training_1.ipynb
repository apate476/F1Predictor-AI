{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f282521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 dataset: (1398, 27)\n",
      "2026 dataset: (22, 19)\n",
      "\n",
      "2025 columns:\n",
      "['year', 'round', 'race_name', 'circuit', 'date', 'driver', 'driver_name', 'team', 'grid_position', 'finish_position', 'outperformance', 'dnf', 'rolling_avg_finish_5', 'rolling_avg_points_5', 'constructor_rolling_points_5', 'dnf_rate', 'driver_experience', 'season_stage', 'circuit_type', 'overtaking_difficulty', 'safety_car_probability', 'is_sprint_weekend', 'avg_team_pit_seconds', 'quali_position', 'rolling_avg_quali_5', 'teammate_quali_gap', 'sample_weight']\n",
      "\n",
      "2026 columns:\n",
      "['driver', 'test1_best_s', 'test2_best_s', 'test1_gap_s', 'test2_gap_s', 'testing_improvement_s', 'combined_pace_gap_s', 'team_2026', 'total_testing_laps', 'avg_race_pace_s', 'race_pace_gap_s', 'team_total_laps', 'team_reliability_score', 'driver_team_change', 'new_team_flag', 'rookie_flag', 'barcelona_best_s', 'barcelona_gap_s', 'missed_barcelona']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Load both datasets\n",
    "df_2025 = pd.read_csv('../data/master_features_all.csv')\n",
    "df_2026 = pd.read_csv('../data/features_2026.csv')\n",
    "\n",
    "print(f\"2025 dataset: {df_2025.shape}\")\n",
    "print(f\"2026 dataset: {df_2026.shape}\")\n",
    "print(f\"\\n2025 columns:\\n{df_2025.columns.tolist()}\")\n",
    "print(f\"\\n2026 columns:\\n{df_2026.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28ae063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: finish_position\n",
      "Number of features: 16\n",
      "\n",
      "Features:\n",
      "  1. grid_position\n",
      "  2. outperformance\n",
      "  3. rolling_avg_finish_5\n",
      "  4. rolling_avg_points_5\n",
      "  5. constructor_rolling_points_5\n",
      "  6. dnf_rate\n",
      "  7. driver_experience\n",
      "  8. overtaking_difficulty\n",
      "  9. safety_car_probability\n",
      "  10. is_sprint_weekend\n",
      "  11. avg_team_pit_seconds\n",
      "  12. quali_position\n",
      "  13. rolling_avg_quali_5\n",
      "  14. teammate_quali_gap\n",
      "  15. stage_early\n",
      "  16. stage_mid\n",
      "\n",
      "TRAIN / TEST SPLIT:\n",
      "Training rows : 1278 (2023+2024+2025 Rounds 1-18)\n",
      "Test rows     : 120 (2025 Rounds 19-24)\n"
     ]
    }
   ],
   "source": [
    "# FEATURE PREP + TRAIN/TEST SPLIT\n",
    "\n",
    "TARGET = 'finish_position'\n",
    "\n",
    "META_COLS = [\n",
    "    'year', 'race_name', 'circuit', \n",
    "    'date', 'driver', 'driver_name', 'team'\n",
    "]\n",
    "\n",
    "LEAKAGE_COLS = [\n",
    "    'status',          \n",
    "    'points',             \n",
    "    'laps_completed',      \n",
    "    'fastest_lap_rank',    \n",
    "    'dnf',                 \n",
    "    'teammate_finish_gap',\n",
    "    'championship_gap',    \n",
    "    'wet_race',\n",
    "    'sample_weight',       # not a feature, used for training only\n",
    "]\n",
    "\n",
    "# ONE HOT ENCODE circuit_type and season_stage\n",
    "df_encoded = pd.get_dummies(\n",
    "    df_2025, \n",
    "    columns=['circuit_type', 'season_stage'], \n",
    "    prefix=['circuit', 'stage']\n",
    ")\n",
    "\n",
    "# SPLIT FIRST — use 2025 data only for train/test split evaluation\n",
    "# Train = 2023 + 2024 + 2025 rounds 1-18\n",
    "# Test  = 2025 rounds 19-24\n",
    "train_mask = ~((df_encoded['year'] == 2025) & (df_encoded['round'] >= 19))\n",
    "test_mask  =   (df_encoded['year'] == 2025) & (df_encoded['round'] >= 19)\n",
    "\n",
    "# NOW drop metadata + leakage + round\n",
    "drop_cols = [c for c in META_COLS + LEAKAGE_COLS + ['round'] \n",
    "             if c in df_encoded.columns]\n",
    "df_encoded = df_encoded.drop(columns=drop_cols)\n",
    "\n",
    "# Feature columns = everything except target\n",
    "feature_cols = [c for c in df_encoded.columns if c != TARGET]\n",
    "\n",
    "# Redundant/useless features based on feature importance\n",
    "WEAK_FEATURES = ['home_race', 'circuit_permanent', 'circuit_street', 'stage_late']\n",
    "feature_cols = [c for c in feature_cols if c not in WEAK_FEATURES]\n",
    "\n",
    "print(f\"Target: {TARGET}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeatures:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "df_train = df_encoded[train_mask].copy()\n",
    "df_test  = df_encoded[test_mask].copy()\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[TARGET]\n",
    "w_train = df_2025[train_mask]['sample_weight']\n",
    "\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[TARGET]\n",
    "\n",
    "print(f\"\\nTRAIN / TEST SPLIT:\")\n",
    "print(f\"Training rows : {len(X_train)} (2023+2024+2025 Rounds 1-18)\")\n",
    "print(f\"Test rows     : {len(X_test)} (2025 Rounds 19-24)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfdc90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.459 positions off on average\n",
      "  e.g. if driver actually finishes P5,\n",
      "  we predict somewhere around P5 to P5\n",
      "\n",
      "SAMPLE PREDICTIONS (first 20 rows):\n",
      "    actual  predicted  error\n",
      "0       14       13.8   -0.2\n",
      "1       12       12.1    0.1\n",
      "2       11       11.1    0.1\n",
      "3       16       15.7   -0.3\n",
      "4       11       11.3    0.3\n",
      "5       16       15.6   -0.4\n",
      "6       13       13.7    0.7\n",
      "7        6        5.2   -0.8\n",
      "8        2        2.4    0.4\n",
      "9        3        4.1    1.1\n",
      "10       5        5.3    0.3\n",
      "11      15       14.2   -0.8\n",
      "12      20       19.4   -0.6\n",
      "13      17       15.6   -1.4\n",
      "14      13       12.9   -0.1\n",
      "15       5        5.8    0.8\n",
      "16       3        3.7    0.7\n",
      "17      13       12.6   -0.4\n",
      "18       3        3.3    0.3\n",
      "19       2        2.0    0.0\n"
     ]
    }
   ],
   "source": [
    "# TRAIN BASELINE LIGHTGBM MODEL\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, sample_weight=w_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae:.3f} positions off on average\")\n",
    "print(f\"  e.g. if driver actually finishes P5,\")\n",
    "print(f\"  we predict somewhere around P{5-mae:.0f} to P{5+mae:.0f}\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'actual'   : y_test.values,\n",
    "    'predicted': y_pred.round(1),\n",
    "    'error'    : (y_pred - y_test.values).round(1)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nSAMPLE PREDICTIONS (first 20 rows):\")\n",
    "print(results_df.head(20).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be558d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE IMPORTANCE:\n",
      "                         feature  importance\n",
      "0                 outperformance        1762\n",
      "1                  grid_position        1073\n",
      "2           avg_team_pit_seconds         825\n",
      "3                 quali_position         735\n",
      "4            rolling_avg_quali_5         682\n",
      "5           rolling_avg_finish_5         553\n",
      "6           rolling_avg_points_5         438\n",
      "7              driver_experience         421\n",
      "8             teammate_quali_gap         402\n",
      "9   constructor_rolling_points_5         383\n",
      "10                      dnf_rate         378\n",
      "11        safety_car_probability         239\n",
      "12         overtaking_difficulty          79\n",
      "13             is_sprint_weekend          63\n",
      "14                     stage_mid          53\n",
      "15                   stage_early          49\n"
     ]
    }
   ],
   "source": [
    "# FEATURE IMPORTANCE\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature'   : feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"FEATURE IMPORTANCE:\")\n",
    "print(importance_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd66ca3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f5c7726b1142a4884bc532bdf5fa01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE : 0.380\n",
      "Best params:\n",
      "{'n_estimators': 959, 'learning_rate': 0.04575664966316788, 'max_depth': 3, 'num_leaves': 31, 'min_child_samples': 6, 'subsample': 0.9588949742036352, 'colsample_bytree': 0.8180684991304144}\n"
     ]
    }
   ],
   "source": [
    "# OPTUNA HYPERPARAMETER TUNING (single split)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators'     : trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth'        : trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves'       : trial.suggest_int('num_leaves', 15, 127),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'subsample'        : trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'random_state'     : 42,\n",
    "        'verbose'          : -1\n",
    "    }\n",
    "    m = lgb.LGBMRegressor(**params)\n",
    "    m.fit(X_train, y_train, sample_weight=w_train)\n",
    "    y_pred = m.predict(X_test)\n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=300, show_progress_bar=True)\n",
    "print(f\"Best MAE : {study.best_value:.3f}\")\n",
    "print(f\"Best params:\\n{study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6ff88",
   "metadata": {},
   "source": [
    "Baseline (default params)  →  0.635 MAE\n",
    "After dropping weak features →  0.512 MAE\n",
    "After Optuna tuning          →  0.438 MAE\n",
    "\n",
    "Total improvement: 0.197 positions ✅\n",
    "\n",
    "learning_rate = 0.125   → higher than our 0.05 guess\n",
    "max_depth = 10          → deeper trees than we used\n",
    "num_leaves = 22         → fewer leaves than default 31\n",
    "n_estimators = 457      → more trees than our 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb093e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MAE: 0.380 positions off on average\n",
      "\n",
      "Sample predictions (first 20 rows):\n",
      "    actual  predicted  error\n",
      "0       14       13.7   -0.3\n",
      "1       12       12.1    0.1\n",
      "2       11       11.2    0.2\n",
      "3       16       15.8   -0.2\n",
      "4       11       11.3    0.3\n",
      "5       16       16.0    0.0\n",
      "6       13       13.4    0.4\n",
      "7        6        5.3   -0.7\n",
      "8        2        2.5    0.5\n",
      "9        3        4.0    1.0\n",
      "10       5        4.9   -0.1\n",
      "11      15       15.6    0.6\n",
      "12      20       19.3   -0.7\n",
      "13      17       15.9   -1.1\n",
      "14      13       12.8   -0.2\n",
      "15       5        5.5    0.5\n",
      "16       3        4.1    1.1\n",
      "17      13       12.3   -0.7\n",
      "18       3        3.1    0.1\n",
      "19       2        1.7   -0.3\n"
     ]
    }
   ],
   "source": [
    "# RETRAIN WITH BEST PARAMS\n",
    "\n",
    "best_model = lgb.LGBMRegressor(**study.best_params, random_state=42, verbose=-1)\n",
    "best_model.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Final MAE: {mae_best:.3f} positions off on average\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'actual'   : y_test.values,\n",
    "    'predicted': y_pred_best.round(1),\n",
    "    'error'    : (y_pred_best - y_test.values).round(1)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nSample predictions (first 20 rows):\")\n",
    "print(results_df.head(20).to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341dcbd4",
   "metadata": {},
   "source": [
    "# OPTUNA SINGLE SPLIT (baseline tuning, reference only)\n",
    "# Note: this overfit to Rounds 19-24, replaced by Cell 8 CV tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d545875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2023) | Train MAE: 0.099 | Test MAE: 0.669 | Gap: 0.570\n",
      "Fold 2 (2024) | Train MAE: 0.069 | Test MAE: 0.766 | Gap: 0.697\n",
      "Fold 3 (2025) | Train MAE: 0.105 | Test MAE: 0.467 | Gap: 0.362\n",
      "\n",
      "Average test MAE : 0.634\n",
      "Std deviation    : 0.125\n",
      "\n",
      "If gap is small (<0.2) → healthy fit\n",
      "If gap is large (>0.5) → overfitting\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION — ROUND-BASED PER YEAR\n",
    "\n",
    "folds = [\n",
    "    (df_2025[df_2025['year'] == 2023]['round'].isin(range(1, 19)),\n",
    "     df_2025[df_2025['year'] == 2023]['round'].isin(range(19, 23))),\n",
    "    (df_2025[df_2025['year'] == 2024]['round'].isin(range(1, 19)),\n",
    "     df_2025[df_2025['year'] == 2024]['round'].isin(range(19, 25))),\n",
    "    (df_2025[df_2025['year'] == 2025]['round'].isin(range(1, 19)),\n",
    "     df_2025[df_2025['year'] == 2025]['round'].isin(range(19, 25))),\n",
    "]\n",
    "\n",
    "fold_maes = []\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(folds, 1):\n",
    "    year = [2023, 2024, 2025][i-1]\n",
    "\n",
    "    df_cv = pd.get_dummies(df_2025[df_2025['year'] == year],\n",
    "                           columns=['circuit_type', 'season_stage'],\n",
    "                           prefix=['circuit', 'stage'])\n",
    "    drop_cols_cv = [c for c in META_COLS + LEAKAGE_COLS + ['round']\n",
    "                    if c in df_cv.columns]\n",
    "    df_cv = df_cv.drop(columns=drop_cols_cv)\n",
    "\n",
    "    X_tr = df_cv[train_idx][feature_cols]\n",
    "    y_tr = df_cv[train_idx][TARGET]\n",
    "    w_tr = df_2025[(df_2025['year'] == year)][train_idx]['sample_weight']\n",
    "    X_te = df_cv[test_idx][feature_cols]\n",
    "    y_te = df_cv[test_idx][TARGET]\n",
    "\n",
    "    cv_model = lgb.LGBMRegressor(**study.best_params, random_state=42, verbose=-1)\n",
    "    cv_model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "\n",
    "    train_mae = mean_absolute_error(y_tr, cv_model.predict(X_tr))\n",
    "    test_mae  = mean_absolute_error(y_te, cv_model.predict(X_te))\n",
    "    gap       = test_mae - train_mae\n",
    "\n",
    "    fold_maes.append(test_mae)\n",
    "    print(f\"Fold {i} ({year}) | Train MAE: {train_mae:.3f} | Test MAE: {test_mae:.3f} | Gap: {gap:.3f}\")\n",
    "\n",
    "print(f\"\\nAverage test MAE : {np.mean(fold_maes):.3f}\")\n",
    "print(f\"Std deviation    : {np.std(fold_maes):.3f}\")\n",
    "print(f\"\\nIf gap is small (<0.2) → healthy fit\")\n",
    "print(f\"If gap is large (>0.5) → overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbd1c96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f3c1a5b0624f7abe242817fd4d2d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV MAE : 0.632\n",
      "Best params : {'n_estimators': 544, 'learning_rate': 0.11418141890472619, 'max_depth': 5, 'num_leaves': 17, 'min_child_samples': 11, 'subsample': 0.6589433698971362, 'colsample_bytree': 0.9865453888942938, 'reg_alpha': 0.22478621228495935, 'reg_lambda': 0.5321437752310665}\n"
     ]
    }
   ],
   "source": [
    "# OPTUNA WITH CROSS VALIDATION OBJECTIVE (year-based folds)\n",
    "\n",
    "def cv_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators'     : trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth'        : trial.suggest_int('max_depth', 3, 6),\n",
    "        'num_leaves'       : trial.suggest_int('num_leaves', 15, 63),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
    "        'subsample'        : trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha'        : trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda'       : trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'random_state'     : 42,\n",
    "        'verbose'          : -1\n",
    "    }\n",
    "\n",
    "    fold_maes = []\n",
    "    for year, test_end in [(2023, 23), (2024, 25), (2025, 25)]:\n",
    "        year_mask  = df_2025['year'] == year\n",
    "        train_idx  = year_mask & df_2025['round'].isin(range(1, 19))\n",
    "        test_idx   = year_mask & df_2025['round'].isin(range(19, test_end))\n",
    "\n",
    "        df_cv = pd.get_dummies(df_2025[year_mask],\n",
    "                               columns=['circuit_type', 'season_stage'],\n",
    "                               prefix=['circuit', 'stage'])\n",
    "        drop_cols_cv = [c for c in META_COLS + LEAKAGE_COLS + ['round']\n",
    "                        if c in df_cv.columns]\n",
    "        df_cv = df_cv.drop(columns=drop_cols_cv)\n",
    "\n",
    "        # Realign index for boolean mask\n",
    "        train_idx_local = df_2025[year_mask]['round'].isin(range(1, 19)).values\n",
    "        test_idx_local  = df_2025[year_mask]['round'].isin(range(19, test_end)).values\n",
    "\n",
    "        X_tr = df_cv[train_idx_local][feature_cols]\n",
    "        y_tr = df_cv[train_idx_local][TARGET]\n",
    "        w_tr = df_2025[year_mask][train_idx_local]['sample_weight']\n",
    "        X_te = df_cv[test_idx_local][feature_cols]\n",
    "        y_te = df_cv[test_idx_local][TARGET]\n",
    "\n",
    "        m = lgb.LGBMRegressor(**params)\n",
    "        m.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "        fold_maes.append(mean_absolute_error(y_te, m.predict(X_te)))\n",
    "\n",
    "    return np.mean(fold_maes)\n",
    "\n",
    "cv_study = optuna.create_study(direction='minimize')\n",
    "cv_study.optimize(cv_objective, n_trials=300, show_progress_bar=True)\n",
    "\n",
    "print(f\"Best CV MAE : {cv_study.best_value:.3f}\")\n",
    "print(f\"Best params : {cv_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a268f757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2023) | Train MAE: 0.077 | Test MAE: 0.645 | Gap: 0.568\n",
      "Fold 2 (2024) | Train MAE: 0.047 | Test MAE: 0.771 | Gap: 0.725\n",
      "Fold 3 (2025) | Train MAE: 0.053 | Test MAE: 0.481 | Gap: 0.428\n",
      "\n",
      "Average test MAE : 0.632\n",
      "Std deviation    : 0.119\n"
     ]
    }
   ],
   "source": [
    "# VERIFY FIT WITH CV PARAMS\n",
    "\n",
    "fold_maes = []\n",
    "\n",
    "for i, (year, test_end) in enumerate([(2023, 23), (2024, 25), (2025, 25)], 1):\n",
    "    year_mask = df_2025['year'] == year\n",
    "\n",
    "    df_cv = pd.get_dummies(df_2025[year_mask],\n",
    "                           columns=['circuit_type', 'season_stage'],\n",
    "                           prefix=['circuit', 'stage'])\n",
    "    drop_cols_cv = [c for c in META_COLS + LEAKAGE_COLS + ['round']\n",
    "                    if c in df_cv.columns]\n",
    "    df_cv = df_cv.drop(columns=drop_cols_cv)\n",
    "\n",
    "    train_idx = df_2025[year_mask]['round'].isin(range(1, 19)).values\n",
    "    test_idx  = df_2025[year_mask]['round'].isin(range(19, test_end)).values\n",
    "\n",
    "    X_tr = df_cv[train_idx][feature_cols]\n",
    "    y_tr = df_cv[train_idx][TARGET]\n",
    "    w_tr = df_2025[year_mask][train_idx]['sample_weight']\n",
    "    X_te = df_cv[test_idx][feature_cols]\n",
    "    y_te = df_cv[test_idx][TARGET]\n",
    "\n",
    "    cv_model = lgb.LGBMRegressor(**cv_study.best_params, random_state=42, verbose=-1)\n",
    "    cv_model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "\n",
    "    train_mae = mean_absolute_error(y_tr, cv_model.predict(X_tr))\n",
    "    test_mae  = mean_absolute_error(y_te, cv_model.predict(X_te))\n",
    "    gap       = test_mae - train_mae\n",
    "\n",
    "    fold_maes.append(test_mae)\n",
    "    print(f\"Fold {i} ({year}) | Train MAE: {train_mae:.3f} | Test MAE: {test_mae:.3f} | Gap: {gap:.3f}\")\n",
    "\n",
    "print(f\"\\nAverage test MAE : {np.mean(fold_maes):.3f}\")\n",
    "print(f\"Std deviation    : {np.std(fold_maes):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "350d16b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained on 1398 rows\n",
      "  2023: 440 rows (weight 0.5)\n",
      "  2024: 479 rows (weight 0.8)\n",
      "  2025: 479 rows (weight 1.0)\n",
      "Features used: 16\n",
      "Reported CV MAE: 0.632\n"
     ]
    }
   ],
   "source": [
    "# RETRAIN FINAL MODEL ON ALL DATA (2023+2024+2025)\n",
    "\n",
    "df_full = pd.get_dummies(df_2025, columns=['circuit_type', 'season_stage'],\n",
    "                         prefix=['circuit', 'stage'])\n",
    "\n",
    "drop_cols_full = [c for c in META_COLS + LEAKAGE_COLS + ['round']\n",
    "                  if c in df_full.columns]\n",
    "\n",
    "w_full = df_2025['sample_weight']\n",
    "df_full = df_full.drop(columns=drop_cols_full)\n",
    "\n",
    "X_full = df_full[feature_cols]\n",
    "y_full = df_full[TARGET]\n",
    "\n",
    "final_model = lgb.LGBMRegressor(**cv_study.best_params, random_state=42, verbose=-1)\n",
    "final_model.fit(X_full, y_full, sample_weight=w_full)\n",
    "\n",
    "print(f\"Final model trained on {len(X_full)} rows\")\n",
    "print(f\"  2023: {(df_2025['year']==2023).sum()} rows (weight 0.5)\")\n",
    "print(f\"  2024: {(df_2025['year']==2024).sum()} rows (weight 0.8)\")\n",
    "print(f\"  2025: {(df_2025['year']==2025).sum()} rows (weight 1.0)\")\n",
    "print(f\"Features used: {len(feature_cols)}\")\n",
    "print(f\"Reported CV MAE: {cv_study.best_value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "805d979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "with open('../models/lgbm_regressor.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "# Save feature list — important for prediction later\n",
    "with open('../models/feature_cols.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_cols, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113cf57",
   "metadata": {},
   "source": [
    "# BUILD 2026 PREDICTION INPUT\n",
    "\n",
    "# Our 2026 features map to 2025 training features like this:\n",
    "# 2025 feature              ← 2026 replacement\n",
    "# rolling_avg_finish_5      ← combined_pace_gap_s (car pace proxy)\n",
    "# constructor_rolling_pts_5 ← team_reliability_score (team form proxy)\n",
    "# avg_team_pit_seconds      ← stays same (pit crew unchanged)\n",
    "# dnf_rate                  ← stays same (driver behaviour unchanged)\n",
    "# quali_position            ← test2_gap_s (qualifying pace proxy)\n",
    "# rolling_avg_quali_5       ← test2_gap_s (same signal)\n",
    "# outperformance            ← stays same (driver talent unchanged)\n",
    "# driver_experience         ← stays same (experience unchanged)\n",
    "# teammate_quali_gap        ← stays same (relative pace unchanged)\n",
    "# grid_position             ← test2_gap_s (starting position proxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30837607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction input shape: (22, 29)\n",
      "Drivers: ['ALB', 'ALO', 'ANT', 'BEA', 'BOR', 'BOT', 'COL', 'GAS', 'HAD', 'HAM', 'HUL', 'LAW', 'LEC', 'LIN', 'NOR', 'OCO', 'PER', 'PIA', 'RUS', 'SAI', 'STR', 'VER']\n",
      "\n",
      "Missing values:\n",
      "barcelona_best_s        3\n",
      "barcelona_gap_s         3\n",
      "outperformance          1\n",
      "driver_experience       1\n",
      "avg_team_pit_seconds    1\n",
      "dnf_rate                1\n",
      "teammate_quali_gap      1\n",
      "rolling_avg_finish_5    1\n",
      "rolling_avg_points_5    1\n",
      "rolling_avg_quali_5     1\n",
      "quali_position          1\n",
      "grid_position           3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# BUILD 2026 PREDICTION INPUT\n",
    "\n",
    "df_26 = pd.read_csv('../data/features_2026.csv')\n",
    "\n",
    "# Use only 2025 data for stable driver features\n",
    "# (most recent season = most relevant baseline)\n",
    "df_2025_only = df_2025[df_2025['year'] == 2025]\n",
    "\n",
    "driver_stable = df_2025_only.groupby('driver').agg(\n",
    "    outperformance        = ('outperformance', 'mean'),\n",
    "    driver_experience     = ('driver_experience', 'mean'),\n",
    "    avg_team_pit_seconds  = ('avg_team_pit_seconds', 'mean'),\n",
    "    dnf_rate              = ('dnf_rate', 'mean'),\n",
    "    teammate_quali_gap    = ('teammate_quali_gap', 'mean'),\n",
    "    rolling_avg_finish_5  = ('rolling_avg_finish_5', 'mean'),\n",
    "    rolling_avg_points_5  = ('rolling_avg_points_5', 'mean'),\n",
    "    rolling_avg_quali_5   = ('rolling_avg_quali_5', 'mean'),\n",
    "    quali_position        = ('quali_position', 'mean'),\n",
    "    grid_position         = ('grid_position', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "# Load BOT and PER 2024 features\n",
    "bot_per = pd.read_csv('../data/bot_per_2024_features.csv')\n",
    "\n",
    "# Combine all 22 drivers\n",
    "driver_all = pd.concat([driver_stable, bot_per], ignore_index=True)\n",
    "\n",
    "# Merge with 2026 testing features\n",
    "df_pred = df_26.merge(driver_all, on='driver', how='left')\n",
    "\n",
    "print(f\"Prediction input shape: {df_pred.shape}\")\n",
    "print(f\"Drivers: {sorted(df_pred['driver'].tolist())}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_pred.isnull().sum()[df_pred.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cb6a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after fix:\n",
      "✅ No missing values!\n",
      "\n",
      "Driver experience after cap:\n",
      "   driver  driver_experience\n",
      "0     ALB              100.0\n",
      "1     ALO              100.0\n",
      "2     ANT                1.0\n",
      "3     BEA               15.0\n",
      "4     BOR                1.0\n",
      "5     BOT              100.0\n",
      "6     COL               10.0\n",
      "7     GAS              100.0\n",
      "8     HAD                1.0\n",
      "9     HAM              100.0\n",
      "10    HUL              100.0\n",
      "11    LAW               20.0\n",
      "12    LEC              100.0\n",
      "13    LIN                0.0\n",
      "14    NOR              100.0\n",
      "15    OCO              100.0\n",
      "16    PER              100.0\n",
      "17    PIA               50.0\n",
      "18    RUS              100.0\n",
      "19    SAI              100.0\n",
      "20    STR              100.0\n",
      "21    VER              100.0\n"
     ]
    }
   ],
   "source": [
    "# HANDLE MISSING VALUES\n",
    "\n",
    "# Barcelona missing — fill with worst gap + penalty\n",
    "worst_barcelona_gap = df_pred['barcelona_gap_s'].max()\n",
    "df_pred['barcelona_gap_s']  = df_pred['barcelona_gap_s'].fillna(worst_barcelona_gap + 1.0)\n",
    "df_pred['barcelona_best_s'] = df_pred['barcelona_best_s'].fillna(df_pred['barcelona_best_s'].max() + 1.0)\n",
    "\n",
    "\n",
    "# LIN — true rookie, use conservative league averages\n",
    "league_avg = driver_stable.mean(numeric_only=True)\n",
    "rookie_cols = ['outperformance', 'driver_experience', 'avg_team_pit_seconds',\n",
    "               'dnf_rate', 'teammate_quali_gap', 'rolling_avg_finish_5',\n",
    "               'rolling_avg_points_5', 'rolling_avg_quali_5', \n",
    "               'quali_position', 'grid_position']\n",
    "\n",
    "for col in rookie_cols:\n",
    "    df_pred.loc[df_pred['driver'] == 'LIN', col] = league_avg[col]\n",
    "\n",
    "# Override driver_experience for LIN manually\n",
    "df_pred.loc[df_pred['driver'] == 'LIN', 'driver_experience'] = 0\n",
    "\n",
    "# BOT and PER missing grid_position — use their quali_position\n",
    "df_pred.loc[df_pred['driver'] == 'BOT', 'grid_position'] = \\\n",
    "    df_pred.loc[df_pred['driver'] == 'BOT', 'quali_position'].values[0]\n",
    "df_pred.loc[df_pred['driver'] == 'PER', 'grid_position'] = \\\n",
    "    df_pred.loc[df_pred['driver'] == 'PER', 'quali_position'].values[0]\n",
    "\n",
    "# Verify\n",
    "print(\"Missing values after fix:\")\n",
    "missing = df_pred.isnull().sum()\n",
    "print(missing[missing > 0] if missing[missing > 0].any() else \"✅ No missing values!\")\n",
    "\n",
    "# Cap driver experience at 100\n",
    "df_pred['driver_experience'] = df_pred['driver_experience'].clip(upper=100)\n",
    "print(f\"\\nDriver experience after cap:\")\n",
    "print(df_pred[['driver', 'driver_experience']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dce6fe13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 circuit features:\n",
      "                    race_name  is_sprint_weekend  overtaking_difficulty  safety_car_probability circuit_type\n",
      "0        Abu Dhabi Grand Prix                  0                    2.0                     0.3    permanent\n",
      "1       Australian Grand Prix                  0                    2.0                     0.7       street\n",
      "2         Austrian Grand Prix                  0                    2.0                     0.5    permanent\n",
      "3       Azerbaijan Grand Prix                  0                    2.0                     0.8       street\n",
      "4          Bahrain Grand Prix                  0                    2.0                     0.3    permanent\n",
      "5          Belgian Grand Prix                  0                    1.0                     0.6    permanent\n",
      "6          British Grand Prix                  1                    2.0                     0.5    permanent\n",
      "7         Canadian Grand Prix                  0                    3.0                     0.7    permanent\n",
      "8          Chinese Grand Prix                  1                    2.0                     0.5    permanent\n",
      "9            Dutch Grand Prix                  0                    3.0                     0.5    permanent\n",
      "10  Emilia Romagna Grand Prix                  0                    3.0                     0.4    permanent\n",
      "11       Hungarian Grand Prix                  0                    4.0                     0.3    permanent\n",
      "12         Italian Grand Prix                  0                    1.0                     0.6    permanent\n",
      "13        Japanese Grand Prix                  0                    3.0                     0.4    permanent\n",
      "14       Las Vegas Grand Prix                  0                    2.0                     0.6       street\n",
      "15     Mexico City Grand Prix                  0                    3.0                     0.5    permanent\n",
      "16           Miami Grand Prix                  1                    3.0                     0.6       street\n",
      "17          Monaco Grand Prix                  0                    5.0                     0.9       street\n",
      "18           Qatar Grand Prix                  1                    3.0                     0.5    permanent\n",
      "19   Saudi Arabian Grand Prix                  0                    2.0                     0.8       street\n",
      "20       Singapore Grand Prix                  1                    4.0                     0.8       street\n",
      "21         Spanish Grand Prix                  0                    3.0                     0.3    permanent\n",
      "22       São Paulo Grand Prix                  1                    3.0                     0.5    permanent\n",
      "23   United States Grand Prix                  0                    2.0                     0.6    permanent\n"
     ]
    }
   ],
   "source": [
    "# BUILD CIRCUIT FEATURES FROM 2025 ONLY\n",
    "\n",
    "circuit_features = df_2025[df_2025['year'] == 2025].groupby('race_name').agg(\n",
    "    is_sprint_weekend      = ('is_sprint_weekend', 'max'),\n",
    "    overtaking_difficulty  = ('overtaking_difficulty', 'first'),\n",
    "    safety_car_probability = ('safety_car_probability', 'first'),\n",
    "    circuit_type           = ('circuit_type', 'first'),\n",
    ").reset_index()\n",
    "\n",
    "print(\"2025 circuit features:\")\n",
    "print(circuit_features.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7852fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing circuit data: 0 races\n",
      "\n",
      "2026 Calendar (24 races):\n",
      "    round                  race_name  is_sprint_weekend  overtaking_difficulty  safety_car_probability  stage_early  stage_mid\n",
      "0       1      Australian Grand Prix                  0                    2.0                     0.7            1          0\n",
      "1       2         Chinese Grand Prix                  1                    2.0                     0.5            1          0\n",
      "2       3        Japanese Grand Prix                  0                    3.0                     0.4            1          0\n",
      "3       4         Bahrain Grand Prix                  0                    2.0                     0.3            1          0\n",
      "4       5   Saudi Arabian Grand Prix                  0                    2.0                     0.8            1          0\n",
      "5       6           Miami Grand Prix                  1                    3.0                     0.6            1          0\n",
      "6       7  Emilia Romagna Grand Prix                  0                    3.0                     0.4            1          0\n",
      "7       8          Monaco Grand Prix                  0                    5.0                     0.9            1          0\n",
      "8       9         Spanish Grand Prix                  0                    3.0                     0.3            0          1\n",
      "9      10        Canadian Grand Prix                  0                    3.0                     0.7            0          1\n",
      "10     11        Austrian Grand Prix                  0                    2.0                     0.5            0          1\n",
      "11     12         British Grand Prix                  1                    2.0                     0.5            0          1\n",
      "12     13         Belgian Grand Prix                  0                    1.0                     0.6            0          1\n",
      "13     14       Hungarian Grand Prix                  0                    4.0                     0.3            0          1\n",
      "14     15           Dutch Grand Prix                  0                    3.0                     0.5            0          1\n",
      "15     16         Italian Grand Prix                  0                    1.0                     0.6            0          1\n",
      "16     17      Azerbaijan Grand Prix                  0                    2.0                     0.8            0          0\n",
      "17     18       Singapore Grand Prix                  1                    4.0                     0.8            0          0\n",
      "18     19   United States Grand Prix                  0                    2.0                     0.6            0          0\n",
      "19     20     Mexico City Grand Prix                  0                    3.0                     0.5            0          0\n",
      "20     21       São Paulo Grand Prix                  1                    3.0                     0.5            0          0\n",
      "21     22       Las Vegas Grand Prix                  0                    2.0                     0.6            0          0\n",
      "22     23           Qatar Grand Prix                  1                    3.0                     0.5            0          0\n",
      "23     24       Abu Dhabi Grand Prix                  0                    2.0                     0.3            0          0\n"
     ]
    }
   ],
   "source": [
    "# BUILD 2026 RACE CALENDAR\n",
    "\n",
    "\n",
    "# 2026 F1 Calendar (24 rounds)\n",
    "calendar_2026 = [\n",
    "    {'round': 1,  'race_name': 'Australian Grand Prix'},\n",
    "    {'round': 2,  'race_name': 'Chinese Grand Prix'},\n",
    "    {'round': 3,  'race_name': 'Japanese Grand Prix'},\n",
    "    {'round': 4,  'race_name': 'Bahrain Grand Prix'},\n",
    "    {'round': 5,  'race_name': 'Saudi Arabian Grand Prix'},\n",
    "    {'round': 6,  'race_name': 'Miami Grand Prix'},\n",
    "    {'round': 7,  'race_name': 'Emilia Romagna Grand Prix'},\n",
    "    {'round': 8,  'race_name': 'Monaco Grand Prix'},\n",
    "    {'round': 9,  'race_name': 'Spanish Grand Prix'},\n",
    "    {'round': 10, 'race_name': 'Canadian Grand Prix'},\n",
    "    {'round': 11, 'race_name': 'Austrian Grand Prix'},\n",
    "    {'round': 12, 'race_name': 'British Grand Prix'},\n",
    "    {'round': 13, 'race_name': 'Belgian Grand Prix'},\n",
    "    {'round': 14, 'race_name': 'Hungarian Grand Prix'},\n",
    "    {'round': 15, 'race_name': 'Dutch Grand Prix'},\n",
    "    {'round': 16, 'race_name': 'Italian Grand Prix'},\n",
    "    {'round': 17, 'race_name': 'Azerbaijan Grand Prix'},\n",
    "    {'round': 18, 'race_name': 'Singapore Grand Prix'},\n",
    "    {'round': 19, 'race_name': 'United States Grand Prix'},\n",
    "    {'round': 20, 'race_name': 'Mexico City Grand Prix'},\n",
    "    {'round': 21, 'race_name': 'São Paulo Grand Prix'},\n",
    "    {'round': 22, 'race_name': 'Las Vegas Grand Prix'},\n",
    "    {'round': 23, 'race_name': 'Qatar Grand Prix'},\n",
    "    {'round': 24, 'race_name': 'Abu Dhabi Grand Prix'},\n",
    "]\n",
    "\n",
    "df_calendar = pd.DataFrame(calendar_2026)\n",
    "\n",
    "# Add season stage\n",
    "df_calendar['stage_early'] = (df_calendar['round'] <= 8).astype(int)\n",
    "df_calendar['stage_mid']   = ((df_calendar['round'] > 8) & (df_calendar['round'] <= 16)).astype(int)\n",
    "\n",
    "# Merge circuit features\n",
    "df_calendar = df_calendar.merge(circuit_features, on='race_name', how='left')\n",
    "\n",
    "# One hot encode circuit_type\n",
    "df_calendar = pd.get_dummies(df_calendar, columns=['circuit_type'], prefix='circuit')\n",
    "\n",
    "# Check missing circuits\n",
    "missing = df_calendar[df_calendar['overtaking_difficulty'].isna()]\n",
    "print(f\"Missing circuit data: {len(missing)} races\")\n",
    "if len(missing) > 0:\n",
    "    print(missing[['round', 'race_name']])\n",
    "\n",
    "print(f\"\\n2026 Calendar ({len(df_calendar)} races):\")\n",
    "print(df_calendar[['round', 'race_name', 'is_sprint_weekend', \n",
    "                    'overtaking_difficulty', 'safety_car_probability',\n",
    "                    'stage_early', 'stage_mid']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58ac0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base predictions done (24 races)\n",
      "✅ 10,000 simulations complete!\n",
      "\n",
      "*** 2026 MONTE CARLO CHAMPIONSHIP PREDICTION ***\n",
      " position driver  avg_points  win_pct  min_points  max_points\n",
      "        1    LEC       410.2     40.8       245.0       538.0\n",
      "        2    RUS       348.7     16.8       236.0       474.0\n",
      "        3    PIA       331.0     15.7       214.0       454.0\n",
      "        4    VER       298.6      8.9       194.0       397.0\n",
      "        5    NOR       272.4      8.2       143.0       388.0\n",
      "        6    HAM       251.1      7.0       136.0       377.0\n",
      "        7    ANT       181.2      2.4        77.0       293.0\n",
      "        8    BEA       105.9      0.1        36.0       182.0\n",
      "        9    ALB        50.2      0.0        12.0       107.0\n",
      "       10    OCO        45.6      0.0         7.0       107.0\n",
      "       11    HUL        34.8      0.0         4.0        88.0\n",
      "       12    HAD        22.6      0.0         0.0        61.0\n",
      "       13    LIN        22.1      0.0         0.0        61.0\n",
      "       14    SAI        13.4      0.0         0.0        44.0\n",
      "       15    LAW        12.3      0.0         0.0        45.0\n",
      "       16    GAS         8.2      0.0         0.0        41.0\n",
      "       17    COL         6.8      0.0         0.0        41.0\n",
      "       18    BOR         3.8      0.0         0.0        25.0\n",
      "       19    STR         1.7      0.0         0.0        18.0\n",
      "       20    PER         1.3      0.0         0.0        17.0\n",
      "       21    ALO         1.0      0.0         0.0        13.0\n",
      "       22    BOT         0.9      0.0         0.0        12.0\n"
     ]
    }
   ],
   "source": [
    "# MONTE CARLO SIMULATION (10,000 runs)\n",
    "\n",
    "\n",
    "N_SIMULATIONS = 10000\n",
    "POINTS = {1:25, 2:18, 3:15, 4:12, 5:10, 6:8, 7:6, 8:4, 9:2, 10:1}\n",
    "\n",
    "drivers = df_pred['driver'].tolist()\n",
    "dnf_rates = df_pred.set_index('driver')['dnf_rate'].to_dict()\n",
    "\n",
    "# STEP 1 — Get base predictions for all 24 races ONCE\n",
    "base_preds = {}\n",
    "for _, race in df_calendar.iterrows():\n",
    "    race_df = df_pred.copy()\n",
    "    race_df['is_sprint_weekend']            = race['is_sprint_weekend']\n",
    "    race_df['overtaking_difficulty']        = race['overtaking_difficulty']\n",
    "    race_df['safety_car_probability']       = race['safety_car_probability']\n",
    "    race_df['stage_early']                  = race['stage_early']\n",
    "    race_df['stage_mid']                    = race['stage_mid']\n",
    "    race_df['grid_position']               = 1 + (race_df['combined_pace_gap_s'] / 0.3)\n",
    "    race_df['quali_position']              = race_df['grid_position']\n",
    "    race_df['rolling_avg_quali_5']         = race_df['grid_position']\n",
    "    race_df['rolling_avg_finish_5']        = race_df['grid_position']\n",
    "    race_df['constructor_rolling_points_5'] = race_df['team_reliability_score'] * 100\n",
    "    base_preds[race['round']] = final_model.predict(race_df[feature_cols])\n",
    "\n",
    "print(\"✅ Base predictions done (24 races)\")\n",
    "\n",
    "# STEP 2 — Monte Carlo in pure numpy (fast)\n",
    "sim_points = np.zeros((N_SIMULATIONS, len(drivers)))\n",
    "sim_wins   = np.zeros(len(drivers))\n",
    "\n",
    "dnf_array = np.array([dnf_rates[d] for d in drivers])\n",
    "\n",
    "for sim in range(N_SIMULATIONS):\n",
    "    season_pts = np.zeros(len(drivers))\n",
    "\n",
    "    for rnd, base in base_preds.items():\n",
    "        # Add noise\n",
    "        noise_scale = 0.803 + (race['safety_car_probability'] * 2.0)\n",
    "        noise = np.random.normal(0, noise_scale, size=len(base))\n",
    "        preds = base + noise\n",
    "\n",
    "        # Simulate DNFs\n",
    "        dnf_mask = np.random.random(len(drivers)) < dnf_array\n",
    "        preds[dnf_mask] += 15\n",
    "\n",
    "        # Rank top 20\n",
    "        ranked_idx = np.argsort(preds)[:20]\n",
    "        for pos, idx in enumerate(ranked_idx, 1):\n",
    "            season_pts[idx] += POINTS.get(pos, 0)\n",
    "\n",
    "        sim_wins[ranked_idx[0]] += 1\n",
    "\n",
    "    sim_points[sim] = season_pts\n",
    "\n",
    "print(f\"✅ {N_SIMULATIONS:,} simulations complete!\")\n",
    "\n",
    "# SUMMARISE\n",
    "results = []\n",
    "for i, driver in enumerate(drivers):\n",
    "    results.append({\n",
    "        'driver'    : driver,\n",
    "        'avg_points': round(sim_points[:, i].mean(), 1),\n",
    "        'min_points': round(sim_points[:, i].min(), 1),\n",
    "        'max_points': round(sim_points[:, i].max(), 1),\n",
    "        'win_pct': round(sim_wins[i] / (N_SIMULATIONS * 24) * 100, 1)\n",
    "    })\n",
    "\n",
    "df_sim = pd.DataFrame(results).sort_values('avg_points', ascending=False).reset_index(drop=True)\n",
    "df_sim['position'] = range(1, len(df_sim) + 1)\n",
    "\n",
    "print(\"\\n*** 2026 MONTE CARLO CHAMPIONSHIP PREDICTION ***\")\n",
    "print(df_sim[['position', 'driver', 'avg_points', 'win_pct', \n",
    "              'min_points', 'max_points']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "405d5f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 2026 PREDICTED CONSTRUCTORS CHAMPIONSHIP ***\n",
      " position           team  avg_points  min_points  max_points\n",
      "        1        Ferrari       661.4       436.0       831.0\n",
      "        2        McLaren       603.5       452.0       759.0\n",
      "        3       Mercedes       529.9       382.0       678.0\n",
      "        4       Red Bull       321.2       224.0       430.0\n",
      "        5   Haas F1 Team       151.5        71.0       244.0\n",
      "        6       Williams        63.6        19.0       137.0\n",
      "        7           Audi        38.6         6.0       101.0\n",
      "        8     RB F1 Team        34.4         7.0        83.0\n",
      "        9 Alpine F1 Team        15.0         0.0        51.0\n",
      "       10   Aston Martin         2.7         0.0        25.0\n",
      "       11       Cadillac         2.2         0.0        18.0\n"
     ]
    }
   ],
   "source": [
    "# CELL 20 — MONTE CARLO CONSTRUCTORS CHAMPIONSHIP\n",
    "\n",
    "# Team map from 2026 data\n",
    "team_map = df_pred.set_index('driver')['team_2026'].to_dict()\n",
    "\n",
    "# Add team to simulation results\n",
    "# We need to rebuild from sim_points array\n",
    "\n",
    "constructor_points = {}\n",
    "for i, driver in enumerate(drivers):\n",
    "    team = team_map[driver]\n",
    "    if team not in constructor_points:\n",
    "        constructor_points[team] = np.zeros(N_SIMULATIONS)\n",
    "    constructor_points[team] += sim_points[:, i]\n",
    "\n",
    "# Summarise constructors\n",
    "constructor_results = []\n",
    "for team, points_array in constructor_points.items():\n",
    "    constructor_results.append({\n",
    "        'team'        : team,\n",
    "        'avg_points'  : round(points_array.mean(), 1),\n",
    "        'min_points'  : round(points_array.min(), 1),\n",
    "        'max_points'  : round(points_array.max(), 1),\n",
    "        'champion_pct': round(np.mean(points_array == max(\n",
    "                            v.mean() for v in constructor_points.values()\n",
    "                        )) * 100, 1)\n",
    "    })\n",
    "\n",
    "df_constructors = pd.DataFrame(constructor_results)\\\n",
    "    .sort_values('avg_points', ascending=False).reset_index(drop=True)\n",
    "df_constructors['position'] = range(1, len(df_constructors) + 1)\n",
    "\n",
    "print(\"*** 2026 PREDICTED CONSTRUCTORS CHAMPIONSHIP ***\")\n",
    "print(df_constructors[['position', 'team', 'avg_points', \n",
    "                         'min_points', 'max_points']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab0bba",
   "metadata": {},
   "source": [
    "# Model 2 - Podium Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf03677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
