{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f282521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 dataset: (479, 34)\n",
      "2026 dataset: (22, 19)\n",
      "\n",
      "2025 columns:\n",
      "['year', 'round', 'race_name', 'circuit', 'date', 'driver', 'driver_name', 'team', 'grid_position', 'finish_position', 'points', 'status', 'laps_completed', 'fastest_lap_rank', 'outperformance', 'teammate_finish_gap', 'constructor_rolling_points_5', 'season_stage', 'is_sprint_weekend', 'circuit_type', 'overtaking_difficulty', 'safety_car_probability', 'home_race', 'championship_gap', 'driver_experience', 'wet_race', 'rolling_avg_finish_5', 'rolling_avg_points_5', 'dnf', 'quali_position', 'rolling_avg_quali_5', 'teammate_quali_gap', 'avg_team_pit_seconds', 'dnf_rate']\n",
      "\n",
      "2026 columns:\n",
      "['driver', 'test1_best_s', 'test2_best_s', 'test1_gap_s', 'test2_gap_s', 'testing_improvement_s', 'combined_pace_gap_s', 'team_2026', 'total_testing_laps', 'avg_race_pace_s', 'race_pace_gap_s', 'team_total_laps', 'team_reliability_score', 'driver_team_change', 'new_team_flag', 'rookie_flag', 'barcelona_best_s', 'barcelona_gap_s', 'missed_barcelona']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Load both datasets\n",
    "df_2025 = pd.read_csv('../data/master_features_2025.csv')\n",
    "df_2026 = pd.read_csv('../data/features_2026.csv')\n",
    "\n",
    "print(f\"2025 dataset: {df_2025.shape}\")\n",
    "print(f\"2026 dataset: {df_2026.shape}\")\n",
    "print(f\"\\n2025 columns:\\n{df_2025.columns.tolist()}\")\n",
    "print(f\"\\n2026 columns:\\n{df_2026.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28ae063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: finish_position\n",
      "Number of features: 16\n",
      "\n",
      "Features:\n",
      "  1. grid_position\n",
      "  2. outperformance\n",
      "  3. constructor_rolling_points_5\n",
      "  4. is_sprint_weekend\n",
      "  5. overtaking_difficulty\n",
      "  6. safety_car_probability\n",
      "  7. driver_experience\n",
      "  8. rolling_avg_finish_5\n",
      "  9. rolling_avg_points_5\n",
      "  10. quali_position\n",
      "  11. rolling_avg_quali_5\n",
      "  12. teammate_quali_gap\n",
      "  13. avg_team_pit_seconds\n",
      "  14. dnf_rate\n",
      "  15. stage_early\n",
      "  16. stage_mid\n",
      "\n",
      "TRAIN / TEST SPLIT:\n",
      "Training rows : 359 (Rounds 1-18)\n",
      "Test rows     : 120 (Rounds 19-24)\n"
     ]
    }
   ],
   "source": [
    "# FEATURE PREP + TRAIN/TEST SPLIT\n",
    "\n",
    "TARGET = 'finish_position'\n",
    "\n",
    "META_COLS = [\n",
    "    'year', 'race_name', 'circuit', \n",
    "    'date', 'driver', 'driver_name', 'team'\n",
    "]\n",
    "\n",
    "LEAKAGE_COLS = [\n",
    "    'status',          \n",
    "    'points',             \n",
    "    'laps_completed',      \n",
    "    'fastest_lap_rank',    \n",
    "    'dnf',                 \n",
    "    'teammate_finish_gap', # current race teammate result\n",
    "    'championship_gap',    # calculated using current race points\n",
    "    'wet_race'\n",
    "]\n",
    "\n",
    "# ONE HOT ENCODE circuit_type and season_stage\n",
    "df_2025_encoded = pd.get_dummies(\n",
    "    df_2025, \n",
    "    columns=['circuit_type', 'season_stage'], \n",
    "    prefix=['circuit', 'stage']\n",
    ")\n",
    "\n",
    "# SPLIT FIRST — while round still exists\n",
    "train_mask = df_2025_encoded['round'] <= 18\n",
    "test_mask  = df_2025_encoded['round'] >= 19\n",
    "\n",
    "# NOW drop metadata + leakage + round\n",
    "drop_cols = [c for c in META_COLS + LEAKAGE_COLS + ['round'] \n",
    "             if c in df_2025_encoded.columns]\n",
    "df_2025_encoded = df_2025_encoded.drop(columns=drop_cols)\n",
    "\n",
    "# Feature columns = everything except target\n",
    "feature_cols = [c for c in df_2025_encoded.columns if c != TARGET]\n",
    "\n",
    "# Redundant/useless features based on feature importance\n",
    "WEAK_FEATURES = ['home_race', 'circuit_permanent', 'circuit_street', 'stage_late']\n",
    "feature_cols = [c for c in feature_cols if c not in WEAK_FEATURES]\n",
    "\n",
    "print(f\"Target: {TARGET}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeatures:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "df_train = df_2025_encoded[train_mask].copy()\n",
    "df_test  = df_2025_encoded[test_mask].copy()\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[TARGET]\n",
    "\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[TARGET]\n",
    "\n",
    "print(f\"\\nTRAIN / TEST SPLIT:\")\n",
    "print(f\"Training rows : {len(X_train)} (Rounds 1-18)\")\n",
    "print(f\"Test rows     : {len(X_test)} (Rounds 19-24)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cfdc90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.512 positions off on average\n",
      "  e.g. if driver actually finishes P5,\n",
      "  we predict somewhere around P4 to P6\n",
      "\n",
      "SAMPLE PREDICTIONS (first 20 rows):\n",
      "    actual  predicted  error\n",
      "0       14       13.8   -0.2\n",
      "1       12       12.4    0.4\n",
      "2       11       11.1    0.1\n",
      "3       16       15.6   -0.4\n",
      "4       11       10.9   -0.1\n",
      "5       16       15.7   -0.3\n",
      "6       13       13.1    0.1\n",
      "7        6        6.0    0.0\n",
      "8        2        2.5    0.5\n",
      "9        3        4.9    1.9\n",
      "10       5        5.3    0.3\n",
      "11      15       14.1   -0.9\n",
      "12      20       19.5   -0.5\n",
      "13      17       16.0   -1.0\n",
      "14      13       12.9   -0.1\n",
      "15       5        5.2    0.2\n",
      "16       3        5.9    2.9\n",
      "17      13       12.8   -0.2\n",
      "18       3        3.1    0.1\n",
      "19       2        2.0   -0.0\n"
     ]
    }
   ],
   "source": [
    "# TRAIN BASELINE LIGHTGBM MODEL\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=300,      # number of trees\n",
    "    learning_rate=0.05,    # how fast the model learns\n",
    "    max_depth=6,           # how deep each tree can grow\n",
    "    num_leaves=31,         # max leaves per tree\n",
    "    min_child_samples=5,   # min rows needed to make a leaf\n",
    "    subsample=0.8,         # use 80% of rows per tree\n",
    "    colsample_bytree=0.8,  # use 80% of features per tree\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae:.3f} positions off on average\")\n",
    "print(f\"  e.g. if driver actually finishes P5,\")\n",
    "print(f\"  we predict somewhere around P{5-mae:.0f} to P{5+mae:.0f}\")\n",
    "\n",
    "# Show a sample of predictions vs actual\n",
    "results_df = pd.DataFrame({\n",
    "    'actual'   : y_test.values,\n",
    "    'predicted': y_pred.round(1),\n",
    "    'error'    : (y_pred - y_test.values).round(1)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nSAMPLE PREDICTIONS (first 20 rows):\")\n",
    "print(results_df.head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be558d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE IMPORTANCE:\n",
      "                         feature  importance\n",
      "0                 outperformance        1238\n",
      "1                  grid_position         918\n",
      "2   constructor_rolling_points_5         510\n",
      "3           rolling_avg_finish_5         507\n",
      "4            rolling_avg_quali_5         447\n",
      "5                 quali_position         371\n",
      "6           rolling_avg_points_5         355\n",
      "7              driver_experience         230\n",
      "8             teammate_quali_gap         165\n",
      "9         safety_car_probability         142\n",
      "10          avg_team_pit_seconds         121\n",
      "11         overtaking_difficulty         110\n",
      "12                      dnf_rate          80\n",
      "13                   stage_early          55\n",
      "14             is_sprint_weekend          53\n",
      "15                     stage_mid          29\n"
     ]
    }
   ],
   "source": [
    "# FEATURE IMPORTANCE\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature'   : feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"FEATURE IMPORTANCE:\")\n",
    "print(importance_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd66ca3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abc0e6f7b0647a285e9052a32b1492c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE : 0.423\n",
      "Best params:\n",
      "{'n_estimators': 928, 'learning_rate': 0.030584726948076943, 'max_depth': 4, 'num_leaves': 113, 'min_child_samples': 5, 'subsample': 0.9806479033001241, 'colsample_bytree': 0.9670031408281698}\n"
     ]
    }
   ],
   "source": [
    "# Optuna Hyperparameter tuning\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators'     : trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth'        : trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves'       : trial.suggest_int('num_leaves', 15, 127),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'subsample'        : trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'random_state'     : 42,\n",
    "        'verbose'          : -1\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Run 100 trials and find the best parameters\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=300, show_progress_bar=True)\n",
    "print(f\"Best MAE : {study.best_value:.3f}\")\n",
    "print(f\"Best params:\\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6ff88",
   "metadata": {},
   "source": [
    "Baseline (default params)  →  0.635 MAE\n",
    "After dropping weak features →  0.512 MAE\n",
    "After Optuna tuning          →  0.438 MAE\n",
    "\n",
    "Total improvement: 0.197 positions ✅\n",
    "\n",
    "learning_rate = 0.125   → higher than our 0.05 guess\n",
    "max_depth = 10          → deeper trees than we used\n",
    "num_leaves = 22         → fewer leaves than default 31\n",
    "n_estimators = 457      → more trees than our 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb093e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MAE: 0.423 positions off on average\n",
      "\n",
      "Sample predictions (first 20 rows):\n",
      "    actual  predicted  error\n",
      "0       14       13.8   -0.2\n",
      "1       12       12.3    0.3\n",
      "2       11       11.2    0.2\n",
      "3       16       15.9   -0.1\n",
      "4       11       10.5   -0.5\n",
      "5       16       16.0   -0.0\n",
      "6       13       13.8    0.8\n",
      "7        6        5.6   -0.4\n",
      "8        2        2.7    0.7\n",
      "9        3        4.4    1.4\n",
      "10       5        5.3    0.3\n",
      "11      15       15.2    0.2\n",
      "12      20       19.7   -0.3\n",
      "13      17       16.1   -0.9\n",
      "14      13       13.1    0.1\n",
      "15       5        4.7   -0.3\n",
      "16       3        4.5    1.5\n",
      "17      13       13.3    0.3\n",
      "18       3        3.0    0.0\n",
      "19       2        2.0    0.0\n"
     ]
    }
   ],
   "source": [
    "# RETRAIN WITH BEST PARAMS\n",
    "\n",
    "# Train final model using Optuna's best parameters\n",
    "best_model = lgb.LGBMRegressor(**study.best_params, random_state=42, verbose=-1)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Final MAE: {mae_best:.3f} positions off on average\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'actual'   : y_test.values,\n",
    "    'predicted': y_pred_best.round(1),\n",
    "    'error'    : (y_pred_best - y_test.values).round(1)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nSample predictions (first 20 rows):\")\n",
    "print(results_df.head(20).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341dcbd4",
   "metadata": {},
   "source": [
    "# OPTUNA SINGLE SPLIT (baseline tuning, reference only)\n",
    "# Note: this overfit to Rounds 19-24, replaced by Cell 8 CV tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d545875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | Train MAE: 0.017 | Test MAE: 1.460 | Gap: 1.443\n",
      "Fold 2 | Train MAE: 0.031 | Test MAE: 0.670 | Gap: 0.639\n",
      "Fold 3 | Train MAE: 0.078 | Test MAE: 0.423 | Gap: 0.344\n",
      "\n",
      "Average test MAE : 0.851\n",
      "Std deviation    : 0.442\n",
      "\n",
      "If gap is small (<0.2) → healthy fit\n",
      "If gap is large (>0.5) → overfitting\n"
     ]
    }
   ],
   "source": [
    "folds = [\n",
    "    (list(range(1, 7)),   list(range(7, 13))),\n",
    "    (list(range(1, 13)),  list(range(13, 19))),\n",
    "    (list(range(1, 19)),  list(range(19, 25))),\n",
    "]\n",
    "\n",
    "fold_maes = []\n",
    "\n",
    "for i, (train_rounds, test_rounds) in enumerate(folds, 1):\n",
    "    train_mask_cv = df_2025['round'].isin(train_rounds)\n",
    "    test_mask_cv  = df_2025['round'].isin(test_rounds)\n",
    "\n",
    "    df_cv = pd.get_dummies(df_2025, columns=['circuit_type', 'season_stage'],\n",
    "                           prefix=['circuit', 'stage'])\n",
    "    drop_cols_cv = [c for c in META_COLS + LEAKAGE_COLS + ['round']\n",
    "                    if c in df_cv.columns]\n",
    "    df_cv = df_cv.drop(columns=drop_cols_cv)\n",
    "\n",
    "    X_tr = df_cv[train_mask_cv][feature_cols]\n",
    "    y_tr = df_cv[train_mask_cv][TARGET]\n",
    "    X_te = df_cv[test_mask_cv][feature_cols]\n",
    "    y_te = df_cv[test_mask_cv][TARGET]\n",
    "\n",
    "    cv_model = lgb.LGBMRegressor(**study.best_params, random_state=42, verbose=-1)\n",
    "    cv_model.fit(X_tr, y_tr)\n",
    "\n",
    "    # Check BOTH train and test MAE\n",
    "    train_mae = mean_absolute_error(y_tr, cv_model.predict(X_tr))\n",
    "    test_mae  = mean_absolute_error(y_te, cv_model.predict(X_te))\n",
    "    gap       = test_mae - train_mae\n",
    "\n",
    "    fold_maes.append(test_mae)\n",
    "    print(f\"Fold {i} | Train MAE: {train_mae:.3f} | Test MAE: {test_mae:.3f} | Gap: {gap:.3f}\")\n",
    "\n",
    "print(f\"\\nAverage test MAE : {np.mean(fold_maes):.3f}\")\n",
    "print(f\"Std deviation    : {np.std(fold_maes):.3f}\")\n",
    "print(f\"\\nIf gap is small (<0.2) → healthy fit\")\n",
    "print(f\"If gap is large (>0.5) → overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbd1c96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6019729823d485ab40126476178136d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV MAE : 0.803\n",
      "Best params : {'n_estimators': 970, 'learning_rate': 0.09658197577351804, 'max_depth': 3, 'num_leaves': 33, 'min_child_samples': 11, 'subsample': 0.8027763078172319, 'colsample_bytree': 0.5793885900726659, 'reg_alpha': 0.26223774241852094, 'reg_lambda': 0.44170535546089823}\n"
     ]
    }
   ],
   "source": [
    "# CELL 8 — OPTUNA WITH CROSS VALIDATION OBJECTIVE\n",
    "\n",
    "\n",
    "def cv_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators'     : trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth'        : trial.suggest_int('max_depth', 3, 6),      # capped at 6\n",
    "        'num_leaves'       : trial.suggest_int('num_leaves', 15, 63),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),  # higher min\n",
    "        'subsample'        : trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha'        : trial.suggest_float('reg_alpha', 0.0, 1.0),   # L1 regularisation\n",
    "        'reg_lambda'       : trial.suggest_float('reg_lambda', 0.0, 1.0),  # L2 regularisation\n",
    "        'random_state'     : 42,\n",
    "        'verbose'          : -1\n",
    "    }\n",
    "\n",
    "    folds = [\n",
    "        (list(range(1, 7)),   list(range(7, 13))),\n",
    "        (list(range(1, 13)),  list(range(13, 19))),\n",
    "        (list(range(1, 19)),  list(range(19, 25))),\n",
    "    ]\n",
    "\n",
    "    fold_maes = []\n",
    "    for train_rounds, test_rounds in folds:\n",
    "        train_mask_cv = df_2025['round'].isin(train_rounds)\n",
    "        test_mask_cv  = df_2025['round'].isin(test_rounds)\n",
    "\n",
    "        df_cv = pd.get_dummies(df_2025, columns=['circuit_type', 'season_stage'],\n",
    "                               prefix=['circuit', 'stage'])\n",
    "        drop_cols_cv = [c for c in META_COLS + LEAKAGE_COLS + ['round']\n",
    "                        if c in df_cv.columns]\n",
    "        df_cv = df_cv.drop(columns=drop_cols_cv)\n",
    "\n",
    "        X_tr = df_cv[train_mask_cv][feature_cols]\n",
    "        y_tr = df_cv[train_mask_cv][TARGET]\n",
    "        X_te = df_cv[test_mask_cv][feature_cols]\n",
    "        y_te = df_cv[test_mask_cv][TARGET]\n",
    "\n",
    "        m = lgb.LGBMRegressor(**params)\n",
    "        m.fit(X_tr, y_tr)\n",
    "        fold_maes.append(mean_absolute_error(y_te, m.predict(X_te)))\n",
    "\n",
    "    return np.mean(fold_maes)\n",
    "\n",
    "# Run Optuna with CV objective\n",
    "cv_study = optuna.create_study(direction='minimize')\n",
    "cv_study.optimize(cv_objective, n_trials=300, show_progress_bar=True)\n",
    "\n",
    "print(f\"Best CV MAE : {cv_study.best_value:.3f}\")\n",
    "print(f\"Best params : {cv_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268f757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | Train MAE: 0.105 | Test MAE: 1.220 | Gap: 1.115\n",
      "Fold 2 | Train MAE: 0.073 | Test MAE: 0.688 | Gap: 0.615\n",
      "Fold 3 | Train MAE: 0.083 | Test MAE: 0.501 | Gap: 0.418\n",
      "\n",
      "Average test MAE : 0.803\n",
      "Std deviation    : 0.305\n"
     ]
    }
   ],
   "source": [
    "# VERIFY FIT WITH NEW PARAMS\n",
    "\n",
    "folds = [\n",
    "    (list(range(1, 7)),   list(range(7, 13))),\n",
    "    (list(range(1, 13)),  list(range(13, 19))),\n",
    "    (list(range(1, 19)),  list(range(19, 25))),\n",
    "]\n",
    "\n",
    "fold_maes = []\n",
    "\n",
    "for i, (train_rounds, test_rounds) in enumerate(folds, 1):\n",
    "    train_mask_cv = df_2025['round'].isin(train_rounds)\n",
    "    test_mask_cv  = df_2025['round'].isin(test_rounds)\n",
    "\n",
    "    df_cv = pd.get_dummies(df_2025, columns=['circuit_type', 'season_stage'],\n",
    "                           prefix=['circuit', 'stage'])\n",
    "    drop_cols_cv = [c for c in META_COLS + LEAKAGE_COLS + ['round']\n",
    "                    if c in df_cv.columns]\n",
    "    df_cv = df_cv.drop(columns=drop_cols_cv)\n",
    "\n",
    "    X_tr = df_cv[train_mask_cv][feature_cols]\n",
    "    y_tr = df_cv[train_mask_cv][TARGET]\n",
    "    X_te = df_cv[test_mask_cv][feature_cols]\n",
    "    y_te = df_cv[test_mask_cv][TARGET]\n",
    "\n",
    "    cv_model = lgb.LGBMRegressor(**cv_study.best_params, random_state=42, verbose=-1)\n",
    "    cv_model.fit(X_tr, y_tr)\n",
    "\n",
    "    train_mae = mean_absolute_error(y_tr, cv_model.predict(X_tr))\n",
    "    test_mae  = mean_absolute_error(y_te, cv_model.predict(X_te))\n",
    "    gap       = test_mae - train_mae\n",
    "\n",
    "    fold_maes.append(test_mae)\n",
    "    print(f\"Fold {i} | Train MAE: {train_mae:.3f} | Test MAE: {test_mae:.3f} | Gap: {gap:.3f}\")\n",
    "\n",
    "print(f\"\\nAverage test MAE : {np.mean(fold_maes):.3f}\")\n",
    "print(f\"Std deviation    : {np.std(fold_maes):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "350d16b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained on 479 rows (24 rounds)\n",
      "Features used: 16\n",
      "Reported CV MAE: 0.803\n"
     ]
    }
   ],
   "source": [
    "# CELL 10 — RETRAIN ON FULL 2025 DATASET (ALL 24 ROUNDS)\n",
    "\n",
    "\n",
    "# Re-encode full dataset\n",
    "df_full = pd.get_dummies(df_2025, columns=['circuit_type', 'season_stage'],\n",
    "                         prefix=['circuit', 'stage'])\n",
    "\n",
    "drop_cols_full = [c for c in META_COLS + LEAKAGE_COLS + ['round']\n",
    "                  if c in df_full.columns]\n",
    "df_full = df_full.drop(columns=drop_cols_full)\n",
    "\n",
    "X_full = df_full[feature_cols]\n",
    "y_full = df_full[TARGET]\n",
    "\n",
    "# Train final model on all 24 rounds\n",
    "final_model = lgb.LGBMRegressor(**cv_study.best_params, random_state=42, verbose=-1)\n",
    "final_model.fit(X_full, y_full)\n",
    "\n",
    "print(f\"Final model trained on {len(X_full)} rows ({df_2025['round'].nunique()} rounds)\")\n",
    "print(f\"Features used: {len(feature_cols)}\")\n",
    "print(f\"Reported CV MAE: 0.803\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "805d979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "with open('../models/lgbm_regressor.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "# Save feature list — important for prediction later\n",
    "with open('../models/feature_cols.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_cols, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113cf57",
   "metadata": {},
   "source": [
    "# BUILD 2026 PREDICTION INPUT\n",
    "\n",
    "# Our 2026 features map to 2025 training features like this:\n",
    "# 2025 feature              ← 2026 replacement\n",
    "# rolling_avg_finish_5      ← combined_pace_gap_s (car pace proxy)\n",
    "# constructor_rolling_pts_5 ← team_reliability_score (team form proxy)\n",
    "# avg_team_pit_seconds      ← stays same (pit crew unchanged)\n",
    "# dnf_rate                  ← stays same (driver behaviour unchanged)\n",
    "# quali_position            ← test2_gap_s (qualifying pace proxy)\n",
    "# rolling_avg_quali_5       ← test2_gap_s (same signal)\n",
    "# outperformance            ← stays same (driver talent unchanged)\n",
    "# driver_experience         ← stays same (experience unchanged)\n",
    "# teammate_quali_gap        ← stays same (relative pace unchanged)\n",
    "# grid_position             ← test2_gap_s (starting position proxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30837607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction input shape: (22, 29)\n",
      "Drivers: ['ALB', 'ALO', 'ANT', 'BEA', 'BOR', 'BOT', 'COL', 'GAS', 'HAD', 'HAM', 'HUL', 'LAW', 'LEC', 'LIN', 'NOR', 'OCO', 'PER', 'PIA', 'RUS', 'SAI', 'STR', 'VER']\n",
      "\n",
      "Missing values:\n",
      "barcelona_best_s        3\n",
      "barcelona_gap_s         3\n",
      "outperformance          1\n",
      "driver_experience       1\n",
      "avg_team_pit_seconds    1\n",
      "dnf_rate                1\n",
      "teammate_quali_gap      1\n",
      "rolling_avg_finish_5    1\n",
      "rolling_avg_points_5    1\n",
      "rolling_avg_quali_5     1\n",
      "quali_position          1\n",
      "grid_position           3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load 2026 testing features\n",
    "df_26 = pd.read_csv('../data/features_2026.csv')\n",
    "\n",
    "# Get stable features from 2025 for the 20 drivers who raced\n",
    "driver_stable = df_2025.groupby('driver').agg(\n",
    "    outperformance        = ('outperformance', 'mean'),\n",
    "    driver_experience     = ('driver_experience', 'mean'),\n",
    "    avg_team_pit_seconds  = ('avg_team_pit_seconds', 'mean'),\n",
    "    dnf_rate              = ('dnf_rate', 'mean'),\n",
    "    teammate_quali_gap    = ('teammate_quali_gap', 'mean'),\n",
    "    rolling_avg_finish_5  = ('rolling_avg_finish_5', 'mean'),\n",
    "    rolling_avg_points_5  = ('rolling_avg_points_5', 'mean'),\n",
    "    rolling_avg_quali_5   = ('rolling_avg_quali_5', 'mean'),\n",
    "    quali_position        = ('quali_position', 'mean'),\n",
    "    grid_position         = ('grid_position', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "# Load BOT and PER 2024 features\n",
    "bot_per = pd.read_csv('../data/bot_per_2024_features.csv')\n",
    "\n",
    "# Combine all 22 drivers\n",
    "driver_all = pd.concat([driver_stable, bot_per], ignore_index=True)\n",
    "\n",
    "# Merge with 2026 testing features\n",
    "df_pred = df_26.merge(driver_all, on='driver', how='left')\n",
    "\n",
    "print(f\"Prediction input shape: {df_pred.shape}\")\n",
    "print(f\"Drivers: {sorted(df_pred['driver'].tolist())}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_pred.isnull().sum()[df_pred.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cb6a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after fix:\n",
      "✅ No missing values!\n",
      "\n",
      "Driver experience after cap:\n",
      "   driver  driver_experience\n",
      "0     ALB              100.0\n",
      "1     ALO              100.0\n",
      "2     ANT                1.0\n",
      "3     BEA               15.0\n",
      "4     BOR                1.0\n",
      "5     BOT              100.0\n",
      "6     COL               10.0\n",
      "7     GAS              100.0\n",
      "8     HAD                1.0\n",
      "9     HAM              100.0\n",
      "10    HUL              100.0\n",
      "11    LAW               20.0\n",
      "12    LEC              100.0\n",
      "13    LIN                0.0\n",
      "14    NOR              100.0\n",
      "15    OCO              100.0\n",
      "16    PER              100.0\n",
      "17    PIA               50.0\n",
      "18    RUS              100.0\n",
      "19    SAI              100.0\n",
      "20    STR              100.0\n",
      "21    VER              100.0\n"
     ]
    }
   ],
   "source": [
    "# HANDLE MISSING VALUES\n",
    "\n",
    "# Barcelona missing — fill with worst gap + penalty\n",
    "worst_barcelona_gap = df_pred['barcelona_gap_s'].max()\n",
    "df_pred['barcelona_gap_s']  = df_pred['barcelona_gap_s'].fillna(worst_barcelona_gap + 1.0)\n",
    "df_pred['barcelona_best_s'] = df_pred['barcelona_best_s'].fillna(df_pred['barcelona_best_s'].max() + 1.0)\n",
    "\n",
    "\n",
    "# LIN — true rookie, use conservative league averages\n",
    "league_avg = driver_stable.mean(numeric_only=True)\n",
    "rookie_cols = ['outperformance', 'driver_experience', 'avg_team_pit_seconds',\n",
    "               'dnf_rate', 'teammate_quali_gap', 'rolling_avg_finish_5',\n",
    "               'rolling_avg_points_5', 'rolling_avg_quali_5', \n",
    "               'quali_position', 'grid_position']\n",
    "\n",
    "for col in rookie_cols:\n",
    "    df_pred.loc[df_pred['driver'] == 'LIN', col] = league_avg[col]\n",
    "\n",
    "# Override driver_experience for LIN manually\n",
    "df_pred.loc[df_pred['driver'] == 'LIN', 'driver_experience'] = 0\n",
    "\n",
    "# BOT and PER missing grid_position — use their quali_position\n",
    "df_pred.loc[df_pred['driver'] == 'BOT', 'grid_position'] = \\\n",
    "    df_pred.loc[df_pred['driver'] == 'BOT', 'quali_position'].values[0]\n",
    "df_pred.loc[df_pred['driver'] == 'PER', 'grid_position'] = \\\n",
    "    df_pred.loc[df_pred['driver'] == 'PER', 'quali_position'].values[0]\n",
    "\n",
    "# Verify\n",
    "print(\"Missing values after fix:\")\n",
    "missing = df_pred.isnull().sum()\n",
    "print(missing[missing > 0] if missing[missing > 0].any() else \"✅ No missing values!\")\n",
    "\n",
    "# Cap driver experience at 100\n",
    "df_pred['driver_experience'] = df_pred['driver_experience'].clip(upper=100)\n",
    "print(f\"\\nDriver experience after cap:\")\n",
    "print(df_pred[['driver', 'driver_experience']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dce6fe13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 circuit features:\n",
      "                    race_name  is_sprint_weekend  overtaking_difficulty  safety_car_probability circuit_type\n",
      "0        Abu Dhabi Grand Prix                  0                    2.0                     0.3    permanent\n",
      "1       Australian Grand Prix                  0                    2.0                     0.7       street\n",
      "2         Austrian Grand Prix                  0                    2.0                     0.5    permanent\n",
      "3       Azerbaijan Grand Prix                  0                    2.0                     0.8       street\n",
      "4          Bahrain Grand Prix                  0                    2.0                     0.3    permanent\n",
      "5          Belgian Grand Prix                  0                    1.0                     0.6    permanent\n",
      "6          British Grand Prix                  1                    2.0                     0.5    permanent\n",
      "7         Canadian Grand Prix                  0                    3.0                     0.7    permanent\n",
      "8          Chinese Grand Prix                  1                    2.0                     0.5    permanent\n",
      "9            Dutch Grand Prix                  0                    3.0                     0.5    permanent\n",
      "10  Emilia Romagna Grand Prix                  0                    3.0                     0.4    permanent\n",
      "11       Hungarian Grand Prix                  0                    4.0                     0.3    permanent\n",
      "12         Italian Grand Prix                  0                    1.0                     0.6    permanent\n",
      "13        Japanese Grand Prix                  0                    3.0                     0.4    permanent\n",
      "14       Las Vegas Grand Prix                  0                    2.0                     0.6       street\n",
      "15     Mexico City Grand Prix                  0                    3.0                     0.5    permanent\n",
      "16           Miami Grand Prix                  1                    3.0                     0.6       street\n",
      "17          Monaco Grand Prix                  0                    5.0                     0.9       street\n",
      "18           Qatar Grand Prix                  1                    3.0                     0.5    permanent\n",
      "19   Saudi Arabian Grand Prix                  0                    2.0                     0.8       street\n",
      "20       Singapore Grand Prix                  1                    4.0                     0.8       street\n",
      "21         Spanish Grand Prix                  0                    3.0                     0.3    permanent\n",
      "22       São Paulo Grand Prix                  1                    3.0                     0.5    permanent\n",
      "23   United States Grand Prix                  0                    2.0                     0.6    permanent\n"
     ]
    }
   ],
   "source": [
    "# BUILD FINAL PREDICTION MATRIX\n",
    "\n",
    "circuit_features = df_2025.groupby('race_name').agg(\n",
    "    is_sprint_weekend      = ('is_sprint_weekend', 'max'),\n",
    "    overtaking_difficulty  = ('overtaking_difficulty', 'first'),\n",
    "    safety_car_probability = ('safety_car_probability', 'first'),\n",
    "    circuit_type           = ('circuit_type', 'first'),\n",
    ").reset_index()\n",
    "\n",
    "print(\"2025 circuit features:\")\n",
    "print(circuit_features.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7852fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing circuit data: 0 races\n",
      "\n",
      "2026 Calendar (24 races):\n",
      "    round                  race_name  is_sprint_weekend  overtaking_difficulty  safety_car_probability  stage_early  stage_mid\n",
      "0       1      Australian Grand Prix                  0                    2.0                     0.7            1          0\n",
      "1       2         Chinese Grand Prix                  1                    2.0                     0.5            1          0\n",
      "2       3        Japanese Grand Prix                  0                    3.0                     0.4            1          0\n",
      "3       4         Bahrain Grand Prix                  0                    2.0                     0.3            1          0\n",
      "4       5   Saudi Arabian Grand Prix                  0                    2.0                     0.8            1          0\n",
      "5       6           Miami Grand Prix                  1                    3.0                     0.6            1          0\n",
      "6       7  Emilia Romagna Grand Prix                  0                    3.0                     0.4            1          0\n",
      "7       8          Monaco Grand Prix                  0                    5.0                     0.9            1          0\n",
      "8       9         Spanish Grand Prix                  0                    3.0                     0.3            0          1\n",
      "9      10        Canadian Grand Prix                  0                    3.0                     0.7            0          1\n",
      "10     11        Austrian Grand Prix                  0                    2.0                     0.5            0          1\n",
      "11     12         British Grand Prix                  1                    2.0                     0.5            0          1\n",
      "12     13         Belgian Grand Prix                  0                    1.0                     0.6            0          1\n",
      "13     14       Hungarian Grand Prix                  0                    4.0                     0.3            0          1\n",
      "14     15           Dutch Grand Prix                  0                    3.0                     0.5            0          1\n",
      "15     16         Italian Grand Prix                  0                    1.0                     0.6            0          1\n",
      "16     17      Azerbaijan Grand Prix                  0                    2.0                     0.8            0          0\n",
      "17     18       Singapore Grand Prix                  1                    4.0                     0.8            0          0\n",
      "18     19   United States Grand Prix                  0                    2.0                     0.6            0          0\n",
      "19     20     Mexico City Grand Prix                  0                    3.0                     0.5            0          0\n",
      "20     21       São Paulo Grand Prix                  1                    3.0                     0.5            0          0\n",
      "21     22       Las Vegas Grand Prix                  0                    2.0                     0.6            0          0\n",
      "22     23           Qatar Grand Prix                  1                    3.0                     0.5            0          0\n",
      "23     24       Abu Dhabi Grand Prix                  0                    2.0                     0.3            0          0\n"
     ]
    }
   ],
   "source": [
    "# BUILD 2026 RACE CALENDAR\n",
    "\n",
    "\n",
    "# 2026 F1 Calendar (24 rounds)\n",
    "calendar_2026 = [\n",
    "    {'round': 1,  'race_name': 'Australian Grand Prix'},\n",
    "    {'round': 2,  'race_name': 'Chinese Grand Prix'},\n",
    "    {'round': 3,  'race_name': 'Japanese Grand Prix'},\n",
    "    {'round': 4,  'race_name': 'Bahrain Grand Prix'},\n",
    "    {'round': 5,  'race_name': 'Saudi Arabian Grand Prix'},\n",
    "    {'round': 6,  'race_name': 'Miami Grand Prix'},\n",
    "    {'round': 7,  'race_name': 'Emilia Romagna Grand Prix'},\n",
    "    {'round': 8,  'race_name': 'Monaco Grand Prix'},\n",
    "    {'round': 9,  'race_name': 'Spanish Grand Prix'},\n",
    "    {'round': 10, 'race_name': 'Canadian Grand Prix'},\n",
    "    {'round': 11, 'race_name': 'Austrian Grand Prix'},\n",
    "    {'round': 12, 'race_name': 'British Grand Prix'},\n",
    "    {'round': 13, 'race_name': 'Belgian Grand Prix'},\n",
    "    {'round': 14, 'race_name': 'Hungarian Grand Prix'},\n",
    "    {'round': 15, 'race_name': 'Dutch Grand Prix'},\n",
    "    {'round': 16, 'race_name': 'Italian Grand Prix'},\n",
    "    {'round': 17, 'race_name': 'Azerbaijan Grand Prix'},\n",
    "    {'round': 18, 'race_name': 'Singapore Grand Prix'},\n",
    "    {'round': 19, 'race_name': 'United States Grand Prix'},\n",
    "    {'round': 20, 'race_name': 'Mexico City Grand Prix'},\n",
    "    {'round': 21, 'race_name': 'São Paulo Grand Prix'},\n",
    "    {'round': 22, 'race_name': 'Las Vegas Grand Prix'},\n",
    "    {'round': 23, 'race_name': 'Qatar Grand Prix'},\n",
    "    {'round': 24, 'race_name': 'Abu Dhabi Grand Prix'},\n",
    "]\n",
    "\n",
    "df_calendar = pd.DataFrame(calendar_2026)\n",
    "\n",
    "# Add season stage\n",
    "df_calendar['stage_early'] = (df_calendar['round'] <= 8).astype(int)\n",
    "df_calendar['stage_mid']   = ((df_calendar['round'] > 8) & (df_calendar['round'] <= 16)).astype(int)\n",
    "\n",
    "# Merge circuit features\n",
    "df_calendar = df_calendar.merge(circuit_features, on='race_name', how='left')\n",
    "\n",
    "# One hot encode circuit_type\n",
    "df_calendar = pd.get_dummies(df_calendar, columns=['circuit_type'], prefix='circuit')\n",
    "\n",
    "# Check missing circuits\n",
    "missing = df_calendar[df_calendar['overtaking_difficulty'].isna()]\n",
    "print(f\"Missing circuit data: {len(missing)} races\")\n",
    "if len(missing) > 0:\n",
    "    print(missing[['round', 'race_name']])\n",
    "\n",
    "print(f\"\\n2026 Calendar ({len(df_calendar)} races):\")\n",
    "print(df_calendar[['round', 'race_name', 'is_sprint_weekend', \n",
    "                    'overtaking_difficulty', 'safety_car_probability',\n",
    "                    'stage_early', 'stage_mid']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76acdeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 480\n",
      "\n",
      "=== AUSTRALIA 2026 PREDICTED GRID ===\n",
      "driver  predicted_position  points\n",
      "   VER                   1    25.0\n",
      "   RUS                   2    18.0\n",
      "   PIA                   3    15.0\n",
      "   NOR                   4    12.0\n",
      "   LEC                   5    10.0\n",
      "   HAM                   6     8.0\n",
      "   ALO                   7     6.0\n",
      "   HAD                   8     4.0\n",
      "   ALB                   9     2.0\n",
      "   ANT                  10     1.0\n",
      "   PER                  11     0.0\n",
      "   BEA                  12     0.0\n",
      "   HUL                  13     0.0\n",
      "   OCO                  14     0.0\n",
      "   SAI                  15     0.0\n",
      "   LIN                  16     0.0\n",
      "   LAW                  17     0.0\n",
      "   BOT                  18     0.0\n",
      "   STR                  19     0.0\n",
      "   BOR                  20     0.0\n"
     ]
    }
   ],
   "source": [
    "# GENERATE 2026 PREDICTIONS (RACE BY RACE)\n",
    "\n",
    "POINTS = {1:25, 2:18, 3:15, 4:12, 5:10, 6:8, 7:6, 8:4, 9:2, 10:1}\n",
    "\n",
    "all_race_results = []\n",
    "\n",
    "for _, race in df_calendar.iterrows():\n",
    "    race_df = df_predictions[df_predictions['round'] == race['round']].copy()\n",
    "    \n",
    "    # Keep only top 20 by predicted score\n",
    "    race_df = race_df.sort_values('predicted_score').head(20).copy()\n",
    "    \n",
    "    # Reassign positions 1-20\n",
    "    race_df['predicted_position'] = range(1, 21)\n",
    "    \n",
    "    # Add points\n",
    "    race_df['points'] = race_df['predicted_position'].map(POINTS).fillna(0)\n",
    "    \n",
    "    all_race_results.append(race_df)\n",
    "\n",
    "df_results_2026 = pd.concat(all_race_results, ignore_index=True)\n",
    "\n",
    "print(f\"Total predictions: {len(df_results_2026)}\")\n",
    "print(f\"\\n=== AUSTRALIA 2026 PREDICTED GRID ===\")\n",
    "aus = df_results_2026[df_results_2026['round'] == 1].sort_values('predicted_position')\n",
    "print(aus[['driver', 'predicted_position', 'points']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c88b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 2026 PREDICTED DRIVERS CHAMPIONSHIP ***\n",
      " position driver  total_points\n",
      "        1    VER         600.0\n",
      "        2    RUS         420.0\n",
      "        3    PIA         372.0\n",
      "        4    NOR         286.0\n",
      "        5    LEC         242.0\n",
      "        6    HAM         192.0\n",
      "        7    ALO         144.0\n",
      "        8    HAD          96.0\n",
      "        9    ANT          39.0\n",
      "       10    ALB          20.0\n",
      "       11    PER          13.0\n",
      "       12    BEA           0.0\n",
      "       13    LIN           0.0\n",
      "       14    LAW           0.0\n",
      "       15    HUL           0.0\n",
      "       16    BOR           0.0\n",
      "       17    BOT           0.0\n",
      "       18    OCO           0.0\n",
      "       19    SAI           0.0\n",
      "       20    STR           0.0\n",
      "\n",
      "*** 2026 PREDICTED CONSTRUCTORS CHAMPIONSHIP ***\n",
      " position         team  total_points\n",
      "        1     Red Bull         696.0\n",
      "        2      McLaren         658.0\n",
      "        3     Mercedes         459.0\n",
      "        4      Ferrari         434.0\n",
      "        5 Aston Martin         144.0\n",
      "        6     Williams          20.0\n",
      "        7     Cadillac          13.0\n",
      "        8         Audi           0.0\n",
      "        9 Haas F1 Team           0.0\n",
      "       10   RB F1 Team           0.0\n"
     ]
    }
   ],
   "source": [
    "# CHAMPIONSHIP STANDINGS\n",
    "\n",
    "\n",
    "# DRIVERS CHAMPIONSHIP\n",
    "drivers_championship = df_results_2026.groupby('driver')['points'].sum()\\\n",
    "    .sort_values(ascending=False).reset_index()\n",
    "drivers_championship.columns = ['driver', 'total_points']\n",
    "drivers_championship['position'] = range(1, len(drivers_championship) + 1)\n",
    "\n",
    "print(\"*** 2026 PREDICTED DRIVERS CHAMPIONSHIP ***\")\n",
    "print(drivers_championship[['position', 'driver', 'total_points']].to_string(index=False))\n",
    "\n",
    "# CONSTRUCTORS CHAMPIONSHIP\n",
    "team_map = df_pred.set_index('driver')['team_2026'].to_dict()\n",
    "df_results_2026['team'] = df_results_2026['driver'].map(team_map)\n",
    "\n",
    "constructors_championship = df_results_2026.groupby('team')['points'].sum()\\\n",
    "    .sort_values(ascending=False).reset_index()\n",
    "constructors_championship.columns = ['team', 'total_points']\n",
    "constructors_championship['position'] = range(1, len(constructors_championship) + 1)\n",
    "\n",
    "print(\"\\n*** 2026 PREDICTED CONSTRUCTORS CHAMPIONSHIP ***\")\n",
    "print(constructors_championship[['position', 'team', 'total_points']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58ac0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base predictions done (24 races)\n",
      "✅ 10,000 simulations complete!\n",
      "\n",
      "*** 2026 MONTE CARLO CHAMPIONSHIP PREDICTION ***\n",
      " position driver  avg_points  win_pct  min_points  max_points\n",
      "        1    LEC       428.7     47.0       255.0       555.0\n",
      "        2    RUS       347.8     16.3       222.0       466.0\n",
      "        3    PIA       310.3     11.8       175.0       428.0\n",
      "        4    VER       264.4      5.1       161.0       356.0\n",
      "        5    HAM       259.0      7.7       143.0       397.0\n",
      "        6    NOR       237.4      4.4       120.0       352.0\n",
      "        7    ANT       233.5      7.2       102.0       364.0\n",
      "        8    BEA       128.0      0.4        51.0       213.0\n",
      "        9    ALB        48.0      0.0         8.0       101.0\n",
      "       10    OCO        39.4      0.0         6.0        92.0\n",
      "       11    HUL        28.0      0.0         2.0        76.0\n",
      "       12    LIN        23.3      0.0         1.0        62.0\n",
      "       13    HAD        20.4      0.0         0.0        65.0\n",
      "       14    SAI        18.2      0.0         0.0        55.0\n",
      "       15    LAW        17.7      0.0         0.0        54.0\n",
      "       16    COL         6.3      0.0         0.0        38.0\n",
      "       17    GAS         5.5      0.0         0.0        29.0\n",
      "       18    BOR         3.7      0.0         0.0        23.0\n",
      "       19    PER         1.3      0.0         0.0        14.0\n",
      "       20    ALO         1.3      0.0         0.0        18.0\n",
      "       21    STR         1.2      0.0         0.0        18.0\n",
      "       22    BOT         0.6      0.0         0.0        11.0\n"
     ]
    }
   ],
   "source": [
    "# MONTE CARLO SIMULATION (10,000 runs)\n",
    "\n",
    "\n",
    "N_SIMULATIONS = 10000\n",
    "POINTS = {1:25, 2:18, 3:15, 4:12, 5:10, 6:8, 7:6, 8:4, 9:2, 10:1}\n",
    "\n",
    "drivers = df_pred['driver'].tolist()\n",
    "dnf_rates = df_pred.set_index('driver')['dnf_rate'].to_dict()\n",
    "\n",
    "# STEP 1 — Get base predictions for all 24 races ONCE\n",
    "base_preds = {}\n",
    "for _, race in df_calendar.iterrows():\n",
    "    race_df = df_pred.copy()\n",
    "    race_df['is_sprint_weekend']            = race['is_sprint_weekend']\n",
    "    race_df['overtaking_difficulty']        = race['overtaking_difficulty']\n",
    "    race_df['safety_car_probability']       = race['safety_car_probability']\n",
    "    race_df['stage_early']                  = race['stage_early']\n",
    "    race_df['stage_mid']                    = race['stage_mid']\n",
    "    race_df['grid_position']               = 1 + (race_df['combined_pace_gap_s'] / 0.3)\n",
    "    race_df['quali_position']              = race_df['grid_position']\n",
    "    race_df['rolling_avg_quali_5']         = race_df['grid_position']\n",
    "    race_df['rolling_avg_finish_5']        = race_df['grid_position']\n",
    "    race_df['constructor_rolling_points_5'] = race_df['team_reliability_score'] * 100\n",
    "    base_preds[race['round']] = final_model.predict(race_df[feature_cols])\n",
    "\n",
    "print(\"✅ Base predictions done (24 races)\")\n",
    "\n",
    "# STEP 2 — Monte Carlo in pure numpy (fast)\n",
    "sim_points = np.zeros((N_SIMULATIONS, len(drivers)))\n",
    "sim_wins   = np.zeros(len(drivers))\n",
    "\n",
    "dnf_array = np.array([dnf_rates[d] for d in drivers])\n",
    "\n",
    "for sim in range(N_SIMULATIONS):\n",
    "    season_pts = np.zeros(len(drivers))\n",
    "\n",
    "    for rnd, base in base_preds.items():\n",
    "        # Add noise\n",
    "        noise_scale = 0.803 + (race['safety_car_probability'] * 2.0)\n",
    "        noise = np.random.normal(0, noise_scale, size=len(base))\n",
    "        preds = base + noise\n",
    "\n",
    "        # Simulate DNFs\n",
    "        dnf_mask = np.random.random(len(drivers)) < dnf_array\n",
    "        preds[dnf_mask] += 15\n",
    "\n",
    "        # Rank top 20\n",
    "        ranked_idx = np.argsort(preds)[:20]\n",
    "        for pos, idx in enumerate(ranked_idx, 1):\n",
    "            season_pts[idx] += POINTS.get(pos, 0)\n",
    "\n",
    "        sim_wins[ranked_idx[0]] += 1\n",
    "\n",
    "    sim_points[sim] = season_pts\n",
    "\n",
    "print(f\"✅ {N_SIMULATIONS:,} simulations complete!\")\n",
    "\n",
    "# SUMMARISE\n",
    "results = []\n",
    "for i, driver in enumerate(drivers):\n",
    "    results.append({\n",
    "        'driver'    : driver,\n",
    "        'avg_points': round(sim_points[:, i].mean(), 1),\n",
    "        'min_points': round(sim_points[:, i].min(), 1),\n",
    "        'max_points': round(sim_points[:, i].max(), 1),\n",
    "        'win_pct': round(sim_wins[i] / (N_SIMULATIONS * 24) * 100, 1)\n",
    "    })\n",
    "\n",
    "df_sim = pd.DataFrame(results).sort_values('avg_points', ascending=False).reset_index(drop=True)\n",
    "df_sim['position'] = range(1, len(df_sim) + 1)\n",
    "\n",
    "print(\"\\n*** 2026 MONTE CARLO CHAMPIONSHIP PREDICTION ***\")\n",
    "print(df_sim[['position', 'driver', 'avg_points', 'win_pct', \n",
    "              'min_points', 'max_points']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "405d5f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 2026 PREDICTED CONSTRUCTORS CHAMPIONSHIP ***\n",
      " position           team  avg_points  min_points  max_points\n",
      "        1        Ferrari       687.8       490.0       861.0\n",
      "        2       Mercedes       581.3       404.0       736.0\n",
      "        3        McLaren       547.7       392.0       704.0\n",
      "        4       Red Bull       284.8       183.0       391.0\n",
      "        5   Haas F1 Team       167.4        90.0       271.0\n",
      "        6       Williams        66.2        21.0       129.0\n",
      "        7     RB F1 Team        41.0         6.0        92.0\n",
      "        8           Audi        31.7         4.0        80.0\n",
      "        9 Alpine F1 Team        11.8         0.0        43.0\n",
      "       10   Aston Martin         2.5         0.0        23.0\n",
      "       11       Cadillac         1.9         0.0        19.0\n"
     ]
    }
   ],
   "source": [
    "# CELL 20 — MONTE CARLO CONSTRUCTORS CHAMPIONSHIP\n",
    "\n",
    "# Team map from 2026 data\n",
    "team_map = df_pred.set_index('driver')['team_2026'].to_dict()\n",
    "\n",
    "# Add team to simulation results\n",
    "# We need to rebuild from sim_points array\n",
    "\n",
    "constructor_points = {}\n",
    "for i, driver in enumerate(drivers):\n",
    "    team = team_map[driver]\n",
    "    if team not in constructor_points:\n",
    "        constructor_points[team] = np.zeros(N_SIMULATIONS)\n",
    "    constructor_points[team] += sim_points[:, i]\n",
    "\n",
    "# Summarise constructors\n",
    "constructor_results = []\n",
    "for team, points_array in constructor_points.items():\n",
    "    constructor_results.append({\n",
    "        'team'        : team,\n",
    "        'avg_points'  : round(points_array.mean(), 1),\n",
    "        'min_points'  : round(points_array.min(), 1),\n",
    "        'max_points'  : round(points_array.max(), 1),\n",
    "        'champion_pct': round(np.mean(points_array == max(\n",
    "                            v.mean() for v in constructor_points.values()\n",
    "                        )) * 100, 1)\n",
    "    })\n",
    "\n",
    "df_constructors = pd.DataFrame(constructor_results)\\\n",
    "    .sort_values('avg_points', ascending=False).reset_index(drop=True)\n",
    "df_constructors['position'] = range(1, len(df_constructors) + 1)\n",
    "\n",
    "print(\"*** 2026 PREDICTED CONSTRUCTORS CHAMPIONSHIP ***\")\n",
    "print(df_constructors[['position', 'team', 'avg_points', \n",
    "                         'min_points', 'max_points']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab0bba",
   "metadata": {},
   "source": [
    "# Model 2 - Podium Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022dd4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
